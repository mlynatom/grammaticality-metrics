{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Features\n",
    "\n",
    "Neded to change to correct environment (problems with linkgrammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install pyenchant\n",
    "\n",
    "pip install https://github.com/kpu/kenlm/archive/master.zip\n",
    "\n",
    "and others..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from /home/mlynatom/grammaticality-metrics/heilman-et-al/sentences.txt...\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /home/mlynatom/grammaticality-metrics/native_giga.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /home/mlynatom/grammaticality-metrics/nonnative.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Loading features from /home/mlynatom/grammaticality-metrics/heilman-et-al/sentences.txt\n",
      "0\n",
      "Done. features saved to /home/mlynatom/grammaticality-metrics/regression/features/sentences.txt.json\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!bash /home/mlynatom/grammaticality-metrics/heilman-et-al/test.sh /home/mlynatom/grammaticality-metrics/heilman-et-al/sentences.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import optimize\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeCV, Ridge, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from scipy.stats import pearsonr, kendalltau\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"/home/mlynatom/grammaticality-metrics/heilman-et-al/features/gug_sentences.txt.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3129 entries, 0 to 3128\n",
      "Data columns (total 21 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   3129 non-null   object \n",
      " 1   parse_score          3129 non-null   float64\n",
      " 2   sentential_top_node  3129 non-null   bool   \n",
      " 3   dep_count            3129 non-null   int64  \n",
      " 4   length               3129 non-null   int64  \n",
      " 5   num_miss             3129 non-null   int64  \n",
      " 6   prop_miss            3129 non-null   float64\n",
      " 7   log_miss             3129 non-null   float64\n",
      " 8   min_s_1              3129 non-null   float64\n",
      " 9   max_s_1              3129 non-null   float64\n",
      " 10  sum_s_1              3129 non-null   float64\n",
      " 11  min_s_2              3117 non-null   float64\n",
      " 12  max_s_2              3117 non-null   float64\n",
      " 13  sum_s_2              3117 non-null   float64\n",
      " 14  min_s_3              3106 non-null   float64\n",
      " 15  max_s_3              3106 non-null   float64\n",
      " 16  sum_s_3              3106 non-null   float64\n",
      " 17  giga_oov             3129 non-null   int64  \n",
      " 18  giga_p               3129 non-null   float64\n",
      " 19  toefl11_oov          3129 non-null   int64  \n",
      " 20  toefl11_p            3129 non-null   float64\n",
      "dtypes: bool(1), float64(14), int64(5), object(1)\n",
      "memory usage: 492.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parse_score</th>\n",
       "      <th>sentential_top_node</th>\n",
       "      <th>dep_count</th>\n",
       "      <th>length</th>\n",
       "      <th>num_miss</th>\n",
       "      <th>prop_miss</th>\n",
       "      <th>log_miss</th>\n",
       "      <th>min_s_1</th>\n",
       "      <th>max_s_1</th>\n",
       "      <th>...</th>\n",
       "      <th>min_s_2</th>\n",
       "      <th>max_s_2</th>\n",
       "      <th>sum_s_2</th>\n",
       "      <th>min_s_3</th>\n",
       "      <th>max_s_3</th>\n",
       "      <th>sum_s_3</th>\n",
       "      <th>giga_oov</th>\n",
       "      <th>giga_p</th>\n",
       "      <th>toefl11_oov</th>\n",
       "      <th>toefl11_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gug_sentences.txt.0</td>\n",
       "      <td>-6.017418</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>-4.198308</td>\n",
       "      <td>-1.602172</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.126179</td>\n",
       "      <td>-3.946653</td>\n",
       "      <td>-5.603347</td>\n",
       "      <td>-12.163334</td>\n",
       "      <td>-5.006789</td>\n",
       "      <td>-8.242196</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.871818</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.845929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gug_sentences.txt.1</td>\n",
       "      <td>-6.424152</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>-4.121595</td>\n",
       "      <td>-1.602172</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.526754</td>\n",
       "      <td>-3.737654</td>\n",
       "      <td>-5.590213</td>\n",
       "      <td>-11.925205</td>\n",
       "      <td>-5.921506</td>\n",
       "      <td>-7.897653</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.701693</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.769989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gug_sentences.txt.2</td>\n",
       "      <td>-5.586782</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.269293</td>\n",
       "      <td>-1.602172</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.664845</td>\n",
       "      <td>-3.630444</td>\n",
       "      <td>-5.336554</td>\n",
       "      <td>-8.656352</td>\n",
       "      <td>-6.411362</td>\n",
       "      <td>-7.364122</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.565764</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.999493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gug_sentences.txt.3</td>\n",
       "      <td>-9.942500</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.721482</td>\n",
       "      <td>-1.602172</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.397513</td>\n",
       "      <td>-5.235729</td>\n",
       "      <td>-5.828032</td>\n",
       "      <td>-8.804228</td>\n",
       "      <td>-8.780070</td>\n",
       "      <td>-8.792149</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.631810</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.039621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gug_sentences.txt.4</td>\n",
       "      <td>-6.999736</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.242428</td>\n",
       "      <td>-1.602172</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.033456</td>\n",
       "      <td>-3.934530</td>\n",
       "      <td>-6.281970</td>\n",
       "      <td>-11.981050</td>\n",
       "      <td>-6.278505</td>\n",
       "      <td>-9.136310</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.156215</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.621265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  parse_score  sentential_top_node  dep_count  length  \\\n",
       "0  gug_sentences.txt.0    -6.017418                 True          0      21   \n",
       "1  gug_sentences.txt.1    -6.424152                 True          0      21   \n",
       "2  gug_sentences.txt.2    -5.586782                 True          0      10   \n",
       "3  gug_sentences.txt.3    -9.942500                 True          0       4   \n",
       "4  gug_sentences.txt.4    -6.999736                 True          1      22   \n",
       "\n",
       "   num_miss  prop_miss  log_miss   min_s_1   max_s_1  ...   min_s_2   max_s_2  \\\n",
       "0         1       0.05  0.693147 -4.198308 -1.602172  ... -8.126179 -3.946653   \n",
       "1         2       0.10  1.098612 -4.121595 -1.602172  ... -7.526754 -3.737654   \n",
       "2         0       0.00  0.000000 -4.269293 -1.602172  ... -7.664845 -3.630444   \n",
       "3         0       0.00  0.000000 -3.721482 -1.602172  ... -6.397513 -5.235729   \n",
       "4         0       0.00  0.000000 -4.242428 -1.602172  ... -9.033456 -3.934530   \n",
       "\n",
       "    sum_s_2    min_s_3   max_s_3   sum_s_3  giga_oov    giga_p  toefl11_oov  \\\n",
       "0 -5.603347 -12.163334 -5.006789 -8.242196         2 -2.871818           20   \n",
       "1 -5.590213 -11.925205 -5.921506 -7.897653         3 -2.701693           20   \n",
       "2 -5.336554  -8.656352 -6.411362 -7.364122         1 -2.565764           10   \n",
       "3 -5.828032  -8.804228 -8.780070 -8.792149         1 -4.631810            4   \n",
       "4 -6.281970 -11.981050 -6.278505 -9.136310         1 -3.156215           22   \n",
       "\n",
       "   toefl11_p  \n",
       "0  -0.845929  \n",
       "1  -0.769989  \n",
       "2  -0.999493  \n",
       "3  -2.039621  \n",
       "4  -0.621265  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "gug_data = pd.read_csv(\"/home/mlynatom/grammaticality-metrics/heilman-et-al/gug-data/gug_annotations.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3129 entries, 0 to 3128\n",
      "Data columns (total 6 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Id                       3129 non-null   int64  \n",
      " 1   Sentence                 3129 non-null   object \n",
      " 2   Expert Judgement         3129 non-null   int64  \n",
      " 3   Crowd Flower Judgements  3129 non-null   object \n",
      " 4   Average                  3129 non-null   float64\n",
      " 5   Dataset                  3129 non-null   object \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "gug_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Expert Judgement</th>\n",
       "      <th>Crowd Flower Judgements</th>\n",
       "      <th>Average</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>If the teacher once entered in to the class sh...</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 3, 3, 4, 2]</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>So I think we can not live if old people could...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 1, 2, 3]</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>New and new technology has been introduced to ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 4, 3, 3, 2]</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>For not use car.</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 4, 3, 4, 3]</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Here was no promise of morning except that we ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 4, 3, 2, 3]</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                           Sentence  Expert Judgement  \\\n",
       "0   1  If the teacher once entered in to the class sh...                 3   \n",
       "1   2  So I think we can not live if old people could...                 2   \n",
       "2   3  New and new technology has been introduced to ...                 3   \n",
       "3   4                                   For not use car.                 1   \n",
       "4   5  Here was no promise of morning except that we ...                 3   \n",
       "\n",
       "  Crowd Flower Judgements   Average Dataset  \n",
       "0         [3, 3, 3, 4, 2]  3.000000   train  \n",
       "1         [2, 2, 1, 2, 3]  2.000000    test  \n",
       "2         [3, 4, 3, 3, 2]  3.000000     dev  \n",
       "3         [3, 4, 3, 4, 3]  3.000000    test  \n",
       "4         [2, 4, 3, 2, 3]  2.833333    test  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gug_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parse_score</th>\n",
       "      <th>sentential_top_node</th>\n",
       "      <th>dep_count</th>\n",
       "      <th>length</th>\n",
       "      <th>num_miss</th>\n",
       "      <th>prop_miss</th>\n",
       "      <th>log_miss</th>\n",
       "      <th>min_s_1</th>\n",
       "      <th>max_s_1</th>\n",
       "      <th>...</th>\n",
       "      <th>giga_oov</th>\n",
       "      <th>giga_p</th>\n",
       "      <th>toefl11_oov</th>\n",
       "      <th>toefl11_p</th>\n",
       "      <th>Id</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Expert Judgement</th>\n",
       "      <th>Crowd Flower Judgements</th>\n",
       "      <th>Average</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gug_sentences.txt.0</td>\n",
       "      <td>-6.017418</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>-4.198308</td>\n",
       "      <td>-1.602172</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.871818</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.845929</td>\n",
       "      <td>1</td>\n",
       "      <td>If the teacher once entered in to the class sh...</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 3, 3, 4, 2]</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gug_sentences.txt.1</td>\n",
       "      <td>-6.424152</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>-4.121595</td>\n",
       "      <td>-1.602172</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.701693</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.769989</td>\n",
       "      <td>2</td>\n",
       "      <td>So I think we can not live if old people could...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 1, 2, 3]</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gug_sentences.txt.2</td>\n",
       "      <td>-5.586782</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.269293</td>\n",
       "      <td>-1.602172</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.565764</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.999493</td>\n",
       "      <td>3</td>\n",
       "      <td>New and new technology has been introduced to ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 4, 3, 3, 2]</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gug_sentences.txt.3</td>\n",
       "      <td>-9.942500</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.721482</td>\n",
       "      <td>-1.602172</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.631810</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.039621</td>\n",
       "      <td>4</td>\n",
       "      <td>For not use car.</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 4, 3, 4, 3]</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gug_sentences.txt.4</td>\n",
       "      <td>-6.999736</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.242428</td>\n",
       "      <td>-1.602172</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.156215</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.621265</td>\n",
       "      <td>5</td>\n",
       "      <td>Here was no promise of morning except that we ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 4, 3, 2, 3]</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  parse_score  sentential_top_node  dep_count  length  \\\n",
       "0  gug_sentences.txt.0    -6.017418                 True          0      21   \n",
       "1  gug_sentences.txt.1    -6.424152                 True          0      21   \n",
       "2  gug_sentences.txt.2    -5.586782                 True          0      10   \n",
       "3  gug_sentences.txt.3    -9.942500                 True          0       4   \n",
       "4  gug_sentences.txt.4    -6.999736                 True          1      22   \n",
       "\n",
       "   num_miss  prop_miss  log_miss   min_s_1   max_s_1  ...  giga_oov    giga_p  \\\n",
       "0         1       0.05  0.693147 -4.198308 -1.602172  ...         2 -2.871818   \n",
       "1         2       0.10  1.098612 -4.121595 -1.602172  ...         3 -2.701693   \n",
       "2         0       0.00  0.000000 -4.269293 -1.602172  ...         1 -2.565764   \n",
       "3         0       0.00  0.000000 -3.721482 -1.602172  ...         1 -4.631810   \n",
       "4         0       0.00  0.000000 -4.242428 -1.602172  ...         1 -3.156215   \n",
       "\n",
       "   toefl11_oov  toefl11_p  Id  \\\n",
       "0           20  -0.845929   1   \n",
       "1           20  -0.769989   2   \n",
       "2           10  -0.999493   3   \n",
       "3            4  -2.039621   4   \n",
       "4           22  -0.621265   5   \n",
       "\n",
       "                                            Sentence  Expert Judgement  \\\n",
       "0  If the teacher once entered in to the class sh...                 3   \n",
       "1  So I think we can not live if old people could...                 2   \n",
       "2  New and new technology has been introduced to ...                 3   \n",
       "3                                   For not use car.                 1   \n",
       "4  Here was no promise of morning except that we ...                 3   \n",
       "\n",
       "   Crowd Flower Judgements   Average  Dataset  \n",
       "0          [3, 3, 3, 4, 2]  3.000000    train  \n",
       "1          [2, 2, 1, 2, 3]  2.000000     test  \n",
       "2          [3, 4, 3, 3, 2]  3.000000      dev  \n",
       "3          [3, 4, 3, 4, 3]  3.000000     test  \n",
       "4          [2, 4, 3, 2, 3]  2.833333     test  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_data = pd.concat([data, gug_data], axis=1, )\n",
    "display(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = merged_data[merged_data[\"Expert Judgement\"] != 0] #not valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3019 entries, 0 to 3128\n",
      "Data columns (total 27 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       3019 non-null   object \n",
      " 1   parse_score              3019 non-null   float64\n",
      " 2   sentential_top_node      3019 non-null   bool   \n",
      " 3   dep_count                3019 non-null   int64  \n",
      " 4   length                   3019 non-null   int64  \n",
      " 5   num_miss                 3019 non-null   int64  \n",
      " 6   prop_miss                3019 non-null   float64\n",
      " 7   log_miss                 3019 non-null   float64\n",
      " 8   min_s_1                  3019 non-null   float64\n",
      " 9   max_s_1                  3019 non-null   float64\n",
      " 10  sum_s_1                  3019 non-null   float64\n",
      " 11  min_s_2                  3016 non-null   float64\n",
      " 12  max_s_2                  3016 non-null   float64\n",
      " 13  sum_s_2                  3016 non-null   float64\n",
      " 14  min_s_3                  3014 non-null   float64\n",
      " 15  max_s_3                  3014 non-null   float64\n",
      " 16  sum_s_3                  3014 non-null   float64\n",
      " 17  giga_oov                 3019 non-null   int64  \n",
      " 18  giga_p                   3019 non-null   float64\n",
      " 19  toefl11_oov              3019 non-null   int64  \n",
      " 20  toefl11_p                3019 non-null   float64\n",
      " 21  Id                       3019 non-null   int64  \n",
      " 22  Sentence                 3019 non-null   object \n",
      " 23  Expert Judgement         3019 non-null   int64  \n",
      " 24  Crowd Flower Judgements  3019 non-null   object \n",
      " 25  Average                  3019 non-null   float64\n",
      " 26  Dataset                  3019 non-null   object \n",
      "dtypes: bool(1), float64(15), int64(7), object(4)\n",
      "memory usage: 639.8+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = merged_data[merged_data[\"Dataset\"] == \"train\"]\n",
    "val = merged_data[merged_data[\"Dataset\"] == \"dev\"]\n",
    "test = merged_data[merged_data[\"Dataset\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=[\"id\", \"Id\", \"Sentence\", \"Expert Judgement\", \"Crowd Flower Judgements\", \"Dataset\"])\n",
    "val = val.drop(columns=[\"id\", \"Id\", \"Sentence\", \"Expert Judgement\", \"Crowd Flower Judgements\", \"Dataset\"])\n",
    "test = test.drop(columns=[\"id\", \"Id\", \"Sentence\", \"Expert Judgement\", \"Crowd Flower Judgements\", \"Dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with nans\n",
    "train = train.dropna(axis=0)\n",
    "val = val.dropna(axis=0)\n",
    "test = test.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1516 entries, 0 to 3127\n",
      "Data columns (total 21 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   parse_score          1516 non-null   float64\n",
      " 1   sentential_top_node  1516 non-null   bool   \n",
      " 2   dep_count            1516 non-null   int64  \n",
      " 3   length               1516 non-null   int64  \n",
      " 4   num_miss             1516 non-null   int64  \n",
      " 5   prop_miss            1516 non-null   float64\n",
      " 6   log_miss             1516 non-null   float64\n",
      " 7   min_s_1              1516 non-null   float64\n",
      " 8   max_s_1              1516 non-null   float64\n",
      " 9   sum_s_1              1516 non-null   float64\n",
      " 10  min_s_2              1516 non-null   float64\n",
      " 11  max_s_2              1516 non-null   float64\n",
      " 12  sum_s_2              1516 non-null   float64\n",
      " 13  min_s_3              1516 non-null   float64\n",
      " 14  max_s_3              1516 non-null   float64\n",
      " 15  sum_s_3              1516 non-null   float64\n",
      " 16  giga_oov             1516 non-null   int64  \n",
      " 17  giga_p               1516 non-null   float64\n",
      " 18  toefl11_oov          1516 non-null   int64  \n",
      " 19  toefl11_p            1516 non-null   float64\n",
      " 20  Average              1516 non-null   float64\n",
      "dtypes: bool(1), float64(15), int64(5)\n",
      "memory usage: 250.2 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(\"Average\", axis=1)\n",
    "y_train = train[\"Average\"]\n",
    "\n",
    "X_val = val.drop(\"Average\", axis=1)\n",
    "y_val = val[\"Average\"]\n",
    "\n",
    "X_test = test.drop(\"Average\", axis=1)\n",
    "y_test = test[\"Average\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_scaling(train: pd.DataFrame, val: pd.DataFrame, test: pd.DataFrame, scaler):\n",
    "    X_train_scaled = train\n",
    "    X_val_scaled = val\n",
    "    X_test_scaled = test\n",
    "    if scaler is not None:\n",
    "        # init scaler\n",
    "        scaler = scaler()\n",
    "        X_train_scaled = scaler.fit_transform(train)\n",
    "        X_val_scaled = scaler.transform(val)\n",
    "        X_test_scaled = scaler.transform(test)\n",
    "\n",
    "    return X_train_scaled, X_val_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_val_scaled, X_test_scaled = apply_scaling(X_train, X_val, X_test, StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opt_ridge_model(Xtrain, Xval, ytrain, yval):\n",
    "    def ridgemodel_eval(alpha):\n",
    "        clf = Ridge(alpha=alpha)\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        return mean_squared_error(yval, clf.predict(Xval), squared = False)\n",
    "\n",
    "    # Find Ridge alpha automatically\n",
    "    opt_alpha = optimize.minimize_scalar(ridgemodel_eval, options = {'maxiter': 30}, method = 'bounded', bounds=(0.1, 400))\n",
    "    print('Optimal alpha', opt_alpha)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    clf_opt_ridge = Ridge(alpha = opt_alpha.x)\n",
    "    clf_opt_ridge.fit(Xtrain, ytrain)\n",
    "    return clf_opt_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha  message: Solution found.\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 0.4842792486930455\n",
      "       x: 6.784724038741232\n",
      "     nit: 17\n",
      "    nfev: 17\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt_model = get_opt_ridge_model(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = opt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.5147811722921918, pvalue=4.063340309715265e-52)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.34978430975957125, pvalue=4.9695320518203904e-43)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendalltau(preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(lst):\n",
    "    return [1 if avg > 3.5 else 0 for avg in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_preds_ridge = binarize(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = binarize(y_train)\n",
    "y_val_bin = binarize(y_val)\n",
    "y_test_bin = binarize(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([751,   1]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(bin_preds_ridge, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8457446808510638"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_bin, bin_preds_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.0850107726184491, pvalue=0.0198237341873847)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendalltau(y_test_bin, bin_preds_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGREG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_grid = ParameterGrid({\"l1_ratio\": list(np.arange(0, 1, 0.01))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.26it/s]\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "\n",
    "for params in tqdm(parameters_grid):\n",
    "    tmp_logreg = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=1000, **params)\n",
    "    tmp_logreg.fit(X_train_scaled, y_train_bin)\n",
    "    preds = tmp_logreg.predict(X_val_scaled)\n",
    "    acc.append(accuracy_score(y_val_bin, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_l1 = parameters_grid[np.argmax(acc)][\"l1_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10000, l1_ratio=best_l1)\n",
    "logreg_clf = logreg.fit(X_train, y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(penalty='l2', solver='saga', max_iter=10000)\n",
    "logreg_clf = logreg.fit(X_train, y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_logreg = logreg_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([751,   1]))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(preds_logreg, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8457446808510638"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_bin, preds_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.0850107726184491, pvalue=0.0198237341873847)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendalltau(y_test_bin, preds_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_proba = logreg_clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.45359650306338406, pvalue=1.9471337225020114e-39)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(logreg_proba, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.34611390565949735, pvalue=3.6153055993069564e-42)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendalltau(logreg_proba, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
